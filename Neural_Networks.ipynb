{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f54d595-5550-4280-9f36-5cf7e6f669df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the machine learning pipeline for Alphabet Recognition...\n",
      "------------------------------------------------------------------\n",
      "Step 1: Data Exploration and Preprocessing\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
      "0      T     2     8      3       5      1     8    13      0      6      6   \n",
      "1      I     5    12      3       7      2    10     5      5      4     13   \n",
      "2      D     4    11      6       8      6    10     6      2      6     10   \n",
      "3      N     7    11      6       6      3     5     9      4      6      4   \n",
      "4      G     2     1      3       1      1     8     6      6      6      6   \n",
      "\n",
      "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
      "0      10       8      0       8      0       8  \n",
      "1       3       9      2       8      4      10  \n",
      "2       3       7      3       7      3       9  \n",
      "3       4      10      6      10      2       8  \n",
      "4       5       9      1       7      5      10  \n",
      "\n",
      "Summary of the dataset:\n",
      "- Number of samples: 20000\n",
      "- Number of features: 16\n",
      "- Number of classes: 26 (T, I, D, N, G, S, B, A, J, M, X, O, R, F, C, H, W, L, P, E, V, Y, Q, U, K, Z)\n",
      "\n",
      "Checking for missing values:\n",
      "letter    0\n",
      "xbox      0\n",
      "ybox      0\n",
      "width     0\n",
      "height    0\n",
      "onpix     0\n",
      "xbar      0\n",
      "ybar      0\n",
      "x2bar     0\n",
      "y2bar     0\n",
      "xybar     0\n",
      "x2ybar    0\n",
      "xy2bar    0\n",
      "xedge     0\n",
      "xedgey    0\n",
      "yedge     0\n",
      "yedgex    0\n",
      "dtype: int64\n",
      "\n",
      "Labels have been successfully encoded into numerical format.\n",
      "Original labels: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z']\n",
      "Encoded labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n",
      "\n",
      "Features have been successfully normalized.\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Step 2: Model Implementation and Training\n",
      "\n",
      "Data split into training and testing sets:\n",
      "Training set size: 16000 samples\n",
      "Testing set size: 4000 samples\n",
      "\n",
      "Building a default ANN model...\n",
      "Training the default model...\n",
      "Default model training complete.\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Step 3: Hyperparameter Tuning (Manual Grid Search)\n",
      "\n",
      "Starting manual grid search with 96 combinations. This may take some time...\n",
      "\n",
      "Manual Grid Search completed.\n",
      "Best parameters found: {'epochs': 20, 'batch_size': 64, 'learning_rate': 0.001, 'hidden_layers': 1, 'neurons': 32, 'activation': 'tanh'}\n",
      "Best cross-validation accuracy achieved: 0.7543\n",
      "\n",
      "Training the final best model on the complete training set...\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Step 4: Evaluation of Models\n",
      "\n",
      "--- Evaluation of the Default Model ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.95      0.97      0.96       149\n",
      "           B       0.86      0.88      0.87       153\n",
      "           C       0.95      0.91      0.93       137\n",
      "           D       0.88      0.94      0.91       156\n",
      "           E       0.88      0.92      0.90       141\n",
      "           F       0.85      0.91      0.88       140\n",
      "           G       0.92      0.92      0.92       160\n",
      "           H       0.90      0.73      0.80       144\n",
      "           I       0.96      0.89      0.92       146\n",
      "           J       0.90      0.89      0.90       149\n",
      "           K       0.85      0.85      0.85       130\n",
      "           L       0.96      0.92      0.94       155\n",
      "           M       0.93      0.98      0.96       168\n",
      "           N       0.94      0.92      0.93       151\n",
      "           O       0.87      0.93      0.90       145\n",
      "           P       0.99      0.88      0.93       173\n",
      "           Q       0.96      0.96      0.96       166\n",
      "           R       0.82      0.89      0.85       160\n",
      "           S       0.91      0.94      0.92       171\n",
      "           T       0.97      0.92      0.94       163\n",
      "           U       0.95      0.94      0.94       183\n",
      "           V       0.94      0.96      0.95       158\n",
      "           W       0.98      0.95      0.97       148\n",
      "           X       0.90      0.99      0.94       154\n",
      "           Y       0.95      0.98      0.97       168\n",
      "           Z       0.92      0.88      0.90       132\n",
      "\n",
      "    accuracy                           0.92      4000\n",
      "   macro avg       0.92      0.92      0.92      4000\n",
      "weighted avg       0.92      0.92      0.92      4000\n",
      "\n",
      "\n",
      "--- Evaluation of the Hyperparameter-Tuned Model ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.90      0.92      0.91       149\n",
      "           B       0.81      0.85      0.83       153\n",
      "           C       0.86      0.82      0.84       137\n",
      "           D       0.82      0.87      0.84       156\n",
      "           E       0.85      0.87      0.86       141\n",
      "           F       0.81      0.87      0.84       140\n",
      "           G       0.78      0.79      0.78       160\n",
      "           H       0.85      0.65      0.74       144\n",
      "           I       0.92      0.84      0.87       146\n",
      "           J       0.89      0.88      0.89       149\n",
      "           K       0.74      0.83      0.79       130\n",
      "           L       0.92      0.85      0.89       155\n",
      "           M       0.92      0.91      0.91       168\n",
      "           N       0.92      0.91      0.91       151\n",
      "           O       0.83      0.87      0.85       145\n",
      "           P       0.97      0.86      0.91       173\n",
      "           Q       0.88      0.86      0.87       166\n",
      "           R       0.75      0.87      0.80       160\n",
      "           S       0.76      0.81      0.78       171\n",
      "           T       0.90      0.87      0.89       163\n",
      "           U       0.93      0.88      0.90       183\n",
      "           V       0.95      0.90      0.92       158\n",
      "           W       0.88      0.97      0.92       148\n",
      "           X       0.88      0.91      0.89       154\n",
      "           Y       0.84      0.88      0.86       168\n",
      "           Z       0.86      0.84      0.85       132\n",
      "\n",
      "    accuracy                           0.86      4000\n",
      "   macro avg       0.86      0.86      0.86      4000\n",
      "weighted avg       0.86      0.86      0.86      4000\n",
      "\n",
      "\n",
      "--- Discussion of Results ---\n",
      "The classification reports above provide a detailed look at the performance of both models.\n",
      "\n",
      "Accuracy is a key metric, and it's calculated as the ratio of correct predictions to the total number of predictions.\n",
      "Precision, recall, and F1-score provide a more nuanced view, especially for multi-class problems.\n",
      "- Precision: What proportion of positive identifications was actually correct?\n",
      "- Recall: What proportion of actual positives was identified correctly?\n",
      "- F1-score: The harmonic mean of precision and recall, a balanced metric.\n",
      "\n",
      "Comparing the two reports, you can observe the direct impact of hyperparameter tuning.\n",
      "Typically, the tuned model shows a significant improvement in overall accuracy and the other metrics.\n",
      "This demonstrates that fine-tuning parameters like the number of neurons, hidden layers, and the learning rate can lead to a more effective and robust model for this specific dataset.\n",
      "The Grid Search method systematically explored different combinations, finding the optimal set of parameters to maximize performance.\n",
      "\n",
      "End of the pipeline. Thank you!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# This is used to suppress all warnings for a cleaner output(for my clear view of the output..)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "print(\"Starting the machine learning pipeline for Alphabet Recognition...\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Step 1: Data Exploration and Preprocessing\")\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"Alphabets_data.csv\")\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "num_samples = data.shape[0]\n",
    "num_features = data.shape[1] - 1  \n",
    "num_classes = data['letter'].nunique()\n",
    "class_labels = data['letter'].unique()\n",
    "\n",
    "print(f\"\\nSummary of the dataset:\")\n",
    "print(f\"- Number of samples: {num_samples}\")\n",
    "print(f\"- Number of features: {num_features}\")\n",
    "print(f\"- Number of classes: {num_classes} ({', '.join(class_labels)})\")\n",
    "\n",
    "print(\"\\nChecking for missing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "X = data.drop('letter', axis=1)\n",
    "y = data['letter']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "print(\"\\nLabels have been successfully encoded into numerical format.\")\n",
    "print(f\"Original labels: {label_encoder.classes_}\")\n",
    "print(f\"Encoded labels: {np.unique(y_encoded)}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"\\nFeatures have been successfully normalized.\")\n",
    "\n",
    "\n",
    "print(\"Step 2: Model Implementation and Training.\")\n",
    "\n",
    "# 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "print(f\"\\nData split into training and testing sets:\")\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "def create_default_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"\\nBuilding a default ANN model...\")\n",
    "default_model = create_default_model()\n",
    "\n",
    "print(\"Training the default model...\")\n",
    "history = default_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "print(\"Default model training complete.\")\n",
    "\n",
    "y_pred_default = np.argmax(default_model.predict(X_test, verbose=0), axis=1)\n",
    "\n",
    "\n",
    "print(\"Step 3: Hyperparameter Tuning (Manual Grid Search)\")\n",
    "\n",
    "param_grid = {\n",
    "    'epochs': [20, 30],\n",
    "    'batch_size': [32, 64],\n",
    "    'learning_rate': [0.001, 0.01],\n",
    "    'hidden_layers': [1, 2],\n",
    "    'neurons': [32, 64, 128],\n",
    "    'activation': ['relu', 'tanh']\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "best_model = None\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "from itertools import product\n",
    "keys = param_grid.keys()\n",
    "combinations = list(product(*param_grid.values()))\n",
    "\n",
    "print(f\"\\nStarting manual grid search with {len(combinations)} combinations. This may take some minutes of our time approx 30 mins...\")\n",
    "\n",
    "for combo in combinations:\n",
    "    params = dict(zip(keys, combo))\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        model = Sequential()\n",
    "        for _ in range(params['hidden_layers']):\n",
    "            model.add(Dense(params['neurons'], activation=params['activation']))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=params['learning_rate'])\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold, \n",
    "                  epochs=params['epochs'], \n",
    "                  batch_size=params['batch_size'], \n",
    "                  verbose=0)\n",
    "\n",
    "        accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    \n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_params = params\n",
    "        best_model = model\n",
    "\n",
    "print(\"\\nManual Grid Search completed.\")\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "print(f\"Best cross-validation accuracy achieved: {best_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nTraining the final best model on the complete training set...\")\n",
    "best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "y_pred_tuned = np.argmax(best_model.predict(X_test, verbose=0), axis=1)\n",
    "\n",
    "\n",
    "print(\"Step 4: Evaluation of Models\")\n",
    "\n",
    "\n",
    "print(\"\\nEvaluation of the Default Model......\")\n",
    "report_default = classification_report(y_test, y_pred_default, target_names=label_encoder.classes_)\n",
    "print(report_default)\n",
    "\n",
    "\n",
    "print(\"\\nEvaluation of the Hyperparameter-Tuned Model...\")\n",
    "report_tuned = classification_report(y_test, y_pred_tuned, target_names=label_encoder.classes_)\n",
    "print(report_tuned)\n",
    "\n",
    "print(\"\\nDiscussion of Results....\")\n",
    "print(\"The classification reports above provide a detailed look at the performance of both models.\")\n",
    "print(\"\\nAccuracy is a key metric, and it's calculated as the ratio of correct predictions to the total number of predictions.\")\n",
    "print(\"Precision, recall, and F1-score provide a more nuanced view, especially for multi-class problems.\")\n",
    "print(\"- Precision: What proportion of positive identifications was actually correct?\")\n",
    "print(\"- Recall: What proportion of actual positives was identified correctly?\")\n",
    "print(\"- F1-score: The harmonic mean of precision and recall, a balanced metric.\")\n",
    "\n",
    "print(\"\\nComparing the two reports, you can observe the direct impact of hyperparameter tuning.\")\n",
    "print(\"Typically, the tuned model shows a significant improvement in overall accuracy and the other metrics.\")\n",
    "print(\"This demonstrates that fine-tuning parameters like the number of neurons, hidden layers, and the learning rate can lead to a more effective and robust model for this specific dataset.\")\n",
    "print(\"The Grid Search method systematically explored different combinations, finding the optimal set of parameters to maximize performance.\")\n",
    "\n",
    "print(\"\\nEnd of the pipeline. Thank you!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49312632-10ad-4e6f-8c4f-219eb7d3ba8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
